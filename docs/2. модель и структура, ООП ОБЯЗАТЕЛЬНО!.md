### **Этап 2: Разработка ML/CV компонента (Ядро системы)**

Этот этап является критически важным для всего проекта. Его цель — создать точную, быструю и надежную модель машинного зрения, способную идентифицировать и классифицировать 11 predefined инструментов в условиях, приближенных к реальным (разное освещение, ракурсы, частичные перекрытия).

---

#### **1. Обнаружение объектов (Object Detection)**

**Задача:** Не просто классифицировать изображение целиком, а найти на нем все объекты, определить их границы (ограничивающие рамки - bounding boxes) и присвоить каждому правильный класс (например, "отвертка_плюс", "пассатижи").

**Выбор архитектуры:** **YOLO (You Only Look Once)**. Это современная одноэтапная архитектура, которая предсказывает bounding boxes и классы напрямую за один проход по сети, что обеспечивает высокую скорость обработки, критичную для интерактивного сервиса.

**Библиотеки и фреймворки (Детализация):**

*   **YOLOv8 от Ultralytics:**
    *   **Почему именно v8?** Это одна из последних и наиболее удобных для разработчиков версий. Она предлагает превосходное соотношение точности и скорости, а также чрезвычайно простой API для обучения и инференса.
    *   **Библиотека:** `ultralytics`. Это высокоуровневая обертка вокруг PyTorch, специально разработанная для работы с YOLO.
    *   **Использование:**
        ```python
        from ultralytics import YOLO

        # Загрузка предобученной модели COCO для transfer learning
        model = YOLO('yolov8n.pt')  # n - nano, s - small, m - medium, l - large, x - extra-large

        # Обучение модели на своем датасете
        results = model.train(
            data='dataset/tools_dataset.yaml', # Файл с конфигурацией датасета
            epochs=100,
            imgsz=640,
            batch=16,
            name='yolov8s_tools_detection',
            patience=10 # Остановка обучения, если точность не улучшается 10 эпох
        )

        # Использование для предсказания (инференс)
        results = model('path/to/image.jpg', conf=0.25)  # conf - порог уверенности
        ```
    *   **Вывод результатов:** Объект `results` содержит всю информацию: координаты боксов, уверенность в обнаружении объекта, классы.

*   **OpenCV (cv2):**
    *   **Роль:** Не для построения моделей, а для препроцессинга и постпроцессинга изображений.
    *   **Задачи:**
        *   Чтение изображений/видеопотока с камеры (`cv2.VideoCapture`).
        *   Изменение размера, нормализация цветовых каналов для подачи в нейросеть.
        *   Отрисовка bounding boxes и подписей на итоговом изображении для визуализации.
        *   Операции с цветом (контраст, яркость) как часть аугментации.

*   **PyTorch / TensorFlow:**
    *   **Роль:** YOLOv8 от Ultralytics построена на базе PyTorch. Таким образом, PyTorch является базовым фреймворком. Мы можем не взаимодействовать с ним напрямую благодаря абстракции `ultralytics`, но он необходим "под капотом".

*   **Отечественные альтернативы:**
    *   Требуется исследование реестра ПО. Прямых аналогов YOLO там может не быть.
    *   **Возможный путь:** Использование OpenCV и его модуля `dnn` (Deep Neural Network) для запуска моделей, сконвертированных в форматы `ONNX` или `OpenVINO`. YOLO-модель, обученная через `ultralytics`, легко экспортируется в `ONNX`.
    *   **Пример:** `cv2.dnn.readNetFromONNX('yolov8s_tools.onnx')`. Это может быть представлено как использование отечественной платформы, если она поддерживает запуск ONNX-моделей.

---

#### **2. Данные и аугментация**

Исходных 2000 изображений на инструмент достаточно для начала, но недостаточно для создания робастной модели. Ключ к успеху — искусственное расширение датасета (аугментация).

**a) Разметка данных:**

*   **Инструменты:** **CVAT (Computer Vision Annotation Tool)**. Это мощный open-source веб-инструмент для разметки изображений и видео. Поддерживает команды, имеет удобный интерфейс для рисования bounding boxes и экспорта в форматы YOLO, COCO JSON и др.
*   **Процесс:**
    1.  Загружаем изображения в CVAT.
    2.  Вручную размечаем каждый объект на каждом изображении, обводя его рамкой и присваивая класс из 11 возможных.
    3.  Экспортируем разметку в формате **YOLO** (для каждого изображения создается `.txt` файл, где каждая строка описывает один объект: `class_id center_x center_y width height`; координаты нормализованы от 0 до 1).

**b) Синтез и аугментация данных:**

*   **Зачем это нужно?** Чтобы научить модель быть невосприимчивой к:
    *   Разному освещению (тень, блики).
    *   Разным ракурсам и углам поворота инструментов.
    *   Частичным перекрытиям инструментов друг другом.
    *   Разным фонам (текстура стола, случайные объекты).
*   **Библиотека:** **Albumentations**. Это очень быстрая и гибкая библиотека для аугментации, идеально работающая с задачами детекции.
*   **Пример конвейера аугментации для обучения:**
    ```python
    import albumentations as A
    from albumentations.pytorch import ToTensorV2

    train_transform = A.Compose([
        A.HorizontalFlip(p=0.5),
        A.RandomBrightnessContrast(p=0.2),
        A.RandomGamma(p=0.2),
        A.Blur(blur_limit=3, p=0.1),
        A.RGBShift(r_shift_limit=20, g_shift_limit=20, b_shift_limit=20, p=0.2),
        A.HueSaturationValue(p=0.3),
        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=15, p=0.5),
        # Важно: для детекции нужно также трансформировать bounding boxes!
        A.BboxParams(format='yolo', min_visibility=0.4, label_fields=['class_labels'])
    ], bbox_params=A.BboxParams(format='yolo', min_visibility=0.4, label_fields=['class_labels']))

    # Для валидации и инференса используем только простой препроцессинг
    val_transform = A.Compose([
        A.Normalize(mean=[0,0,0], std=[1,1,1]),
        ToTensorV2(),
    ])
    ```
*   **Синтез сложных сцен:** Мы можем программно создавать изображения всего набора на столе.
    *   **Метод:** Берем изображения каждого инструмента на прозрачном фоне (вырезанные с помощью разметки или фотостудии).
    *   **Библиотека:** `OpenCV`, `PIL`.
    *   **Алгоритм:**
        1.  Генерируем случайный фон (текстура дерева, металла, или однотонный цвет).
        2.  Случайным образом выбираем N инструментов из комплекта.
        3.  Для каждого инструмента: применяем случайное вращение, масштабирование, изменение яркости и накладываем его на фон в случайной позиции, следя за тем, чтобы инструменты не пересекались слишком сильно.
        4.  Автоматически генерируем файл разметки в формате YOLO для合成рованного изображения.
    *   Это позволяет создать десятки тысяч уникальных тренировочных примеров.

---

#### **3. Обучение модели**

**Процесс обучения YOLOv8:**

1.  **Подготовка структуры данных:**
    *   Создается файл `dataset/tools_dataset.yaml`.
    ```yaml
    path: /home/user/tools_dataset
    train: images/train
    val: images/val
    names:
      0: screwdriver_minus
      1: screwdriver_plus
      2: offset_screwdriver
      3: brace
      4: safety_wire_pliers
      5: pliers
      6: shear_nut
      7: adjustable_wrench
      8: oil_can_opener
      9: combination_wrench
      10: side_cutters
    ```
2.  **Разделение данных:** 80% изображений — тренировочный набор, 20% — валидационный.
3.  **Transfer Learning:** Загружаем предобученные веса `yolov8s.pt` (обученные на огромном датасете COCO). Это позволяет модели начать с уже усвоенных признаков (края, текстуры, формы) и значительно ускорить и улучшить обучение на нашей конкретной задаче.
4.  **Подбор гиперпараметров:** Используются встроенные в `ultralytics` инструменты для подбора оптимального learning rate, размера батча и др.
5.  **Мониторинг:** Во время обучения автоматически генерируются логи и графики, отслеживающие ключевые метрики:
    *   **mAP@0.5 (mean Average Precision):** Главная метрика качества детекции. Показывает, насколько точны предсказания модели (чем ближе к 1, тем лучше). Стремимся к значению > 0.95.
    *   **Precision и Recall:** Показывают, сколько из обнаруженных объектов являются правильными (Precision) и сколько правильных объектов было обнаружено (Recall).
    *   **Потери (loss):** Отслеживаем, чтобы значение стабильно уменьшалось и на тренировочном, и на валидационном наборе (избегаем переобучения).

---

#### **4. Верификация и сравнение комплектов**

Это бизнес-логика, которая работает с выходными данными ML-модели.

**Входные данные:**
*   `issued_tools_list` — список инструментов, выданных инженеру (из системы ТОиР). Например: `['screwdriver_plus', 'pliers', 'combination_wrench']`.
*   `detected_tools_list` — список инструментов, которые обнаружила модель на изображении при сдаче. Например: `['pliers', 'combination_wrench']` (отвертка не сдана).

**Алгоритм:**

1.  **Подсчет совпадений:**
    ```python
    def calculate_match_percentage(issued_list, detected_list):
        # Создаем множества для удобства сравнения
        issued_set = set(issued_list)
        detected_set = set(detected_list)

        # Находим инструменты, которые были сданы
        correctly_returned = issued_set & detected_set # Пересечение множеств

        # Находим инструменты, которые НЕ были сданы (потенциальная потеря)
        missing_tools = issued_set - detected_set

        # Находим инструменты, которых не было в выдаче, но они есть на столе (лишние)
        extra_tools = detected_set - issued_set

        # Рассчитываем процент совпадения от выданного комплекта
        match_percentage = (len(correctly_returned) / len(issued_set)) * 100

        return {
            "match_percentage": round(match_percentage, 2),
            "correctly_returned": list(correctly_returned),
            "missing_tools": list(missing_tools),
            "extra_tools": list(extra_tools)
        }
    ```

2.  **Принятие решения:**
    *   Пользовательский порог (например, 95%) настраивается в конфигурации системы.
    *   **Если `match_percentage >= threshold`:** Система автоматически подтверждает операцию, фиксирует результат в БД и системе ТОиР.
    *   **Если `match_percentage < threshold`:** Система инициирует сигнал тревоги. На интерфейсе подсвечиваются `missing_tools` и `extra_tools`. Блокируется автоматическое подтверждение, требуется вмешательство инспектора для ручного пересчета. Факт расхождения также записывается в лог для аудита.

**Важное замечание:** Для учета количества одинаковых инструментов (например, двух одинаковых ключей) алгоритм усложняется. Вместо множеств (`sets`) нужно использовать мультимножества или работать со списками и подсчитывать количество вхождений каждого инструмента.

Это детальное описание обеспечит создание не просто "игрушечной" модели, а промышленного решения, готового к работе в реальных условиях авиационного ангара.
