{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471b164e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "def analyze_image_size(image_path):\n",
    "    \"\"\"Анализирует размер изображения и возвращает нормализованные координаты bbox\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return (0.5, 0.5, 0.8, 0.8)  # fallback values\n",
    "    \n",
    "    height, width = img.shape[:2]\n",
    "    # Предполагаем, что инструмент занимает центральную часть изображения\n",
    "    bbox_width = 0.7 * width\n",
    "    bbox_height = 0.7 * height\n",
    "    x_center = width / 2\n",
    "    y_center = height / 2\n",
    "    \n",
    "    # Нормализованные координаты для YOLO\n",
    "    x_center_norm = x_center / width\n",
    "    y_center_norm = y_center / height\n",
    "    width_norm = bbox_width / width\n",
    "    height_norm = bbox_height / height\n",
    "    \n",
    "    return (x_center_norm, y_center_norm, width_norm, height_norm)\n",
    "\n",
    "def copy_images_with_annotations(src_dir, output_dir, class_idx, split, images, is_single_tool=True):\n",
    "    \"\"\"Копирует изображения и создает аннотации\"\"\"\n",
    "    for img_name in images:\n",
    "        try:\n",
    "            # Копируем изображение\n",
    "            src_img = os.path.join(src_dir, img_name)\n",
    "            dst_img = os.path.join(output_dir, 'images', split, img_name)\n",
    "            shutil.copy2(src_img, dst_img)\n",
    "            \n",
    "            # Создаем YOLO аннотацию\n",
    "            txt_name = os.path.splitext(img_name)[0] + '.txt'\n",
    "            \n",
    "            if is_single_tool:\n",
    "                # Для одиночных инструментов создаем bbox по центру\n",
    "                bbox_coords = analyze_image_size(src_img)\n",
    "                with open(os.path.join(output_dir, 'labels', split, txt_name), 'w') as f:\n",
    "                    f.write(f\"{class_idx} {bbox_coords[0]} {bbox_coords[1]} {bbox_coords[2]} {bbox_coords[3]}\\n\")\n",
    "            else:\n",
    "                # Для групповых и инструментов с линейкой - проверяем существующие аннотации\n",
    "                annotation_path = os.path.join(src_dir, txt_name)\n",
    "                if os.path.exists(annotation_path):\n",
    "                    # Копируем существующую аннотацию\n",
    "                    dst_txt = os.path.join(output_dir, 'labels', split, txt_name)\n",
    "                    shutil.copy2(annotation_path, dst_txt)\n",
    "                else:\n",
    "                    # Создаем пустую аннотацию (требует ручной разметки)\n",
    "                    dst_txt = os.path.join(output_dir, 'labels', split, txt_name)\n",
    "                    open(dst_txt, 'w').close()\n",
    "                    print(f\"  ⚠ Создана пустая аннотация для {img_name} (требует ручной разметки)\")\n",
    "                        \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Ошибка при обработке {img_name}: {e}\")\n",
    "\n",
    "def process_single_tools(dataset_path, output_dir, classes):\n",
    "    \"\"\"Обрабатывает папки с отдельными инструментами\"\"\"\n",
    "    print(\"\\n=== Обработка отдельных инструментов ===\")\n",
    "    \n",
    "    total_images = 0\n",
    "    for class_idx, class_name in enumerate(classes):\n",
    "        class_path = os.path.join(dataset_path, class_name)\n",
    "        \n",
    "        if not os.path.exists(class_path):\n",
    "            print(f\"⚠ Предупреждение: папка {class_path} не существует!\")\n",
    "            continue\n",
    "            \n",
    "        images = [f for f in os.listdir(class_path) \n",
    "                 if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]\n",
    "        \n",
    "        print(f\"{class_name}: {len(images)} изображений\")\n",
    "        \n",
    "        if len(images) == 0:\n",
    "            print(f\"⚠ Предупреждение: в папке {class_name} нет изображений!\")\n",
    "            continue\n",
    "        \n",
    "        # Разделяем на train/val\n",
    "        if len(images) == 1:\n",
    "            train_imgs = images\n",
    "            val_imgs = []\n",
    "        else:\n",
    "            train_imgs, val_imgs = train_test_split(images, test_size=0.2, random_state=42, shuffle=True)\n",
    "        \n",
    "        print(f\"  Train: {len(train_imgs)}, Val: {len(val_imgs)}\")\n",
    "        total_images += len(images)\n",
    "        \n",
    "        # Копируем изображения и создаем аннотации\n",
    "        copy_images_with_annotations(class_path, output_dir, class_idx, 'train', train_imgs, is_single_tool=True)\n",
    "        copy_images_with_annotations(class_path, output_dir, class_idx, 'val', val_imgs, is_single_tool=True)\n",
    "    \n",
    "    print(f\"✓ Обработано отдельных инструментов: {total_images} изображений\")\n",
    "    return total_images\n",
    "\n",
    "def process_tools_with_ruler(dataset_path, output_dir, ruler_folder, classes):\n",
    "    \"\"\"Обрабатывает инструменты с линейкой\"\"\"\n",
    "    print(f\"\\n=== Обработка инструментов с линейкой: {ruler_folder} ===\")\n",
    "    \n",
    "    ruler_path = os.path.join(dataset_path, ruler_folder)\n",
    "    \n",
    "    if not os.path.exists(ruler_path):\n",
    "        print(f\"⚠ Предупреждение: папка {ruler_path} не существует!\")\n",
    "        return 0\n",
    "    \n",
    "    # Создаем маппинг имен инструментов к классам\n",
    "    class_mapping = {}\n",
    "    for class_idx, class_name in enumerate(classes):\n",
    "        class_mapping[class_name] = class_idx\n",
    "    \n",
    "    total_images = 0\n",
    "    images = [f for f in os.listdir(ruler_path) \n",
    "             if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]\n",
    "    \n",
    "    print(f\"Найдено изображений с линейкой: {len(images)}\")\n",
    "    \n",
    "    if len(images) == 0:\n",
    "        print(\"⚠ В папке с линейкой нет изображений!\")\n",
    "        return 0\n",
    "    \n",
    "    # Разделяем на train/val\n",
    "    if len(images) == 1:\n",
    "        train_imgs = images\n",
    "        val_imgs = []\n",
    "    else:\n",
    "        train_imgs, val_imgs = train_test_split(images, test_size=0.2, random_state=42, shuffle=True)\n",
    "    \n",
    "    # Определяем класс для каждого изображения по имени файла\n",
    "    for split, imgs in [('train', train_imgs), ('val', val_imgs)]:\n",
    "        for img_name in imgs:\n",
    "            try:\n",
    "                # Определяем класс инструмента по имени файла\n",
    "                tool_class = None\n",
    "                for class_name in classes:\n",
    "                    if class_name.lower() in img_name.lower():\n",
    "                        tool_class = class_mapping[class_name]\n",
    "                        break\n",
    "                \n",
    "                if tool_class is None:\n",
    "                    print(f\"⚠ Не удалось определить класс для {img_name}\")\n",
    "                    continue\n",
    "                \n",
    "                # Копируем изображение\n",
    "                src_img = os.path.join(ruler_path, img_name)\n",
    "                dst_img = os.path.join(output_dir, 'images', split, img_name)\n",
    "                shutil.copy2(src_img, dst_img)\n",
    "                \n",
    "                # Создаем аннотацию\n",
    "                txt_name = os.path.splitext(img_name)[0] + '.txt'\n",
    "                copy_images_with_annotations(ruler_path, output_dir, tool_class, split, [img_name], is_single_tool=False)\n",
    "                \n",
    "                total_images += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Ошибка при обработке {img_name}: {e}\")\n",
    "    \n",
    "    print(f\"✓ Обработано инструментов с линейкой: {total_images} изображений\")\n",
    "    return total_images\n",
    "\n",
    "def process_group_photos(dataset_path, output_dir, group_folders, classes):\n",
    "    \"\"\"Обрабатывает групповые фотографии инструментов\"\"\"\n",
    "    print(\"\\n=== Обработка групповых фото ===\")\n",
    "    \n",
    "    total_images = 0\n",
    "    for group_folder in group_folders:\n",
    "        group_path = os.path.join(dataset_path, group_folder)\n",
    "        \n",
    "        if not os.path.exists(group_path):\n",
    "            print(f\"⚠ Предупреждение: папка {group_path} не существует!\")\n",
    "            continue\n",
    "            \n",
    "        images = [f for f in os.listdir(group_path) \n",
    "                 if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]\n",
    "        \n",
    "        print(f\"{group_folder}: {len(images)} изображений\")\n",
    "        \n",
    "        if len(images) == 0:\n",
    "            print(f\"⚠ Предупреждение: в папке {group_folder} нет изображений!\")\n",
    "            continue\n",
    "        \n",
    "        # Разделяем на train/val\n",
    "        if len(images) == 1:\n",
    "            train_imgs = images\n",
    "            val_imgs = []\n",
    "        else:\n",
    "            train_imgs, val_imgs = train_test_split(images, test_size=0.2, random_state=42, shuffle=True)\n",
    "        \n",
    "        # Копируем изображения и аннотации\n",
    "        for split, imgs in [('train', train_imgs), ('val', val_imgs)]:\n",
    "            for img_name in imgs:\n",
    "                try:\n",
    "                    # Копируем изображение\n",
    "                    src_img = os.path.join(group_path, img_name)\n",
    "                    dst_img = os.path.join(output_dir, 'images', split, img_name)\n",
    "                    shutil.copy2(src_img, dst_img)\n",
    "                    \n",
    "                    # Копируем аннотацию (если существует)\n",
    "                    txt_name = os.path.splitext(img_name)[0] + '.txt'\n",
    "                    annotation_path = os.path.join(group_path, txt_name)\n",
    "                    \n",
    "                    if os.path.exists(annotation_path):\n",
    "                        dst_txt = os.path.join(output_dir, 'labels', split, txt_name)\n",
    "                        shutil.copy2(annotation_path, dst_txt)\n",
    "                        print(f\"  ✓ Добавлена аннотация для {img_name}\")\n",
    "                    else:\n",
    "                        # Создаем пустую аннотацию\n",
    "                        dst_txt = os.path.join(output_dir, 'labels', split, txt_name)\n",
    "                        open(dst_txt, 'w').close()\n",
    "                        print(f\"  ⚠ Создана пустая аннотация для {img_name} (требует ручной разметки)\")\n",
    "                    \n",
    "                    total_images += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Ошибка при обработке группового фото {img_name}: {e}\")\n",
    "    \n",
    "    print(f\"✓ Обработано групповых фото: {total_images} изображений\")\n",
    "    return total_images\n",
    "\n",
    "def check_dataset_stats(output_dir):\n",
    "    \"\"\"Проверяет статистику подготовленного датасета\"\"\"\n",
    "    print(\"\\n=== Статистика датасета ===\")\n",
    "    \n",
    "    train_images = len(os.listdir(os.path.join(output_dir, 'images', 'train')))\n",
    "    val_images = len(os.listdir(os.path.join(output_dir, 'images', 'val')))\n",
    "    train_labels = len(os.listdir(os.path.join(output_dir, 'labels', 'train')))\n",
    "    val_labels = len(os.listdir(os.path.join(output_dir, 'labels', 'val')))\n",
    "    \n",
    "    print(f\"✓ Тренировочные изображения: {train_images}\")\n",
    "    print(f\"✓ Валидационные изображения: {val_images}\")\n",
    "    print(f\"✓ Тренировочные аннотации: {train_labels}\")\n",
    "    print(f\"✓ Валидационные аннотации: {val_labels}\")\n",
    "    print(f\"✓ Общее количество изображений: {train_images + val_images}\")\n",
    "    \n",
    "    # Проверяем количество объектов в аннотациях\n",
    "    total_objects = 0\n",
    "    for split in ['train', 'val']:\n",
    "        labels_dir = os.path.join(output_dir, 'labels', split)\n",
    "        for label_file in os.listdir(labels_dir):\n",
    "            if label_file.endswith('.txt'):\n",
    "                with open(os.path.join(labels_dir, label_file), 'r') as f:\n",
    "                    objects = len(f.readlines())\n",
    "                    total_objects += objects\n",
    "    \n",
    "    print(f\"✓ Всего объектов в аннотациях: {total_objects}\")\n",
    "\n",
    "def prepare_yolo_dataset(dataset_path, output_dir='yolo_dataset'):\n",
    "    \"\"\"\n",
    "    Подготавливает датасет в формате YOLO для всех типов изображений\n",
    "    \"\"\"\n",
    "    # Получаем все папки\n",
    "    all_folders = sorted([d for d in os.listdir(dataset_path) \n",
    "                         if os.path.isdir(os.path.join(dataset_path, d))])\n",
    "    \n",
    "    print(f\"Найдено папок: {len(all_folders)}\")\n",
    "    print(\"Все папки:\", all_folders)\n",
    "    \n",
    "    # Создаем директории\n",
    "    for split in ['train', 'val']:\n",
    "        os.makedirs(os.path.join(output_dir, 'images', split), exist_ok=True)\n",
    "        os.makedirs(os.path.join(output_dir, 'labels', split), exist_ok=True)\n",
    "    \n",
    "    # Определяем типы папок\n",
    "    tools_folders = [folder for folder in all_folders \n",
    "                    if 'групповые' not in folder.lower() \n",
    "                    and 'линейк' not in folder.lower()\n",
    "                    and 'group' not in folder.lower()\n",
    "                    and 'ruler' not in folder.lower()]\n",
    "    \n",
    "    ruler_folders = [folder for folder in all_folders \n",
    "                    if 'линейк' in folder.lower() \n",
    "                    or 'ruler' in folder.lower()]\n",
    "    \n",
    "    group_folders = [folder for folder in all_folders \n",
    "                    if 'групповые' in folder.lower() \n",
    "                    or 'group' in folder.lower()]\n",
    "    \n",
    "    print(f\"✓ Папки с инструментами: {len(tools_folders)}\")\n",
    "    print(\"Инструменты:\", tools_folders)\n",
    "    print(f\"✓ Папки с линейкой: {len(ruler_folders)}\")\n",
    "    print(\"Линейка:\", ruler_folders)\n",
    "    print(f\"✓ Групповые папки: {len(group_folders)}\")\n",
    "    print(\"Групповые:\", group_folders)\n",
    "    \n",
    "    # Сохраняем классы инструментов\n",
    "    with open(os.path.join(output_dir, 'classes.txt'), 'w') as f:\n",
    "        for i, class_name in enumerate(tools_folders):\n",
    "            f.write(f\"{class_name}\\n\")\n",
    "    \n",
    "    # Обрабатываем все типы данных\n",
    "    single_count = process_single_tools(dataset_path, output_dir, tools_folders)\n",
    "    ruler_count = 0\n",
    "    for ruler_folder in ruler_folders:\n",
    "        ruler_count += process_tools_with_ruler(dataset_path, output_dir, ruler_folder, tools_folders)\n",
    "    \n",
    "    group_count = process_group_photos(dataset_path, output_dir, group_folders, tools_folders)\n",
    "    \n",
    "    # Проверяем результат\n",
    "    check_dataset_stats(output_dir)\n",
    "    \n",
    "    print(f\"\\n📊 ИТОГОВАЯ СТАТИСТИКА:\")\n",
    "    print(f\"  Одиночные инструменты: {single_count}\")\n",
    "    print(f\"  Инструменты с линейкой: {ruler_count}\")\n",
    "    print(f\"  Групповые фото: {group_count}\")\n",
    "    print(f\"  Всего: {single_count + ruler_count + group_count}\")\n",
    "    \n",
    "    return tools_folders\n",
    "\n",
    "def create_dataset_config(output_dir='yolo_dataset', output_yaml='dataset.yaml'):\n",
    "    \"\"\"\n",
    "    Создает конфигурационный файл для датасета YOLO\n",
    "    \"\"\"\n",
    "    # Читаем классы из файла\n",
    "    classes_path = os.path.join(output_dir, 'classes.txt')\n",
    "    if not os.path.exists(classes_path):\n",
    "        print(f\"Ошибка: файл {classes_path} не найден!\")\n",
    "        return None, None\n",
    "    \n",
    "    with open(classes_path, 'r') as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "    # Создаем словарь с конфигурацией\n",
    "    config = {\n",
    "        'path': os.path.abspath(output_dir),\n",
    "        'train': 'images/train',\n",
    "        'val': 'images/val',\n",
    "        'nc': len(classes),\n",
    "        'names': {i: class_name for i, class_name in enumerate(classes)}\n",
    "    }\n",
    "    \n",
    "    # Сохраняем в YAML файл\n",
    "    with open(output_yaml, 'w') as f:\n",
    "        yaml.dump(config, f, default_flow_style=False, allow_unicode=True)\n",
    "    \n",
    "    print(f\"✓ Создан конфиг файл: {output_yaml}\")\n",
    "    print(f\"✓ Путь к данным: {os.path.abspath(output_dir)}\")\n",
    "    print(f\"✓ Количество классов: {len(classes)}\")\n",
    "    print(f\"✓ Классы: {classes}\")\n",
    "    return config, classes\n",
    "\n",
    "def train_yolo_model(output_dir='yolo_dataset', model_size='s', epochs=100):\n",
    "    \"\"\"\n",
    "    Обучение модели YOLOv8 с улучшенными параметрами\n",
    "    \"\"\"\n",
    "    # Создаем конфигурационный файл\n",
    "    config, classes = create_dataset_config(output_dir)\n",
    "    \n",
    "    if config is None:\n",
    "        raise ValueError(\"Не удалось создать конфигурационный файл\")\n",
    "    \n",
    "    # Загружаем предобученную модель\n",
    "    print(f\"🚀 Загрузка модели YOLOv8{model_size}.pt...\")\n",
    "    model = YOLO(f'yolov8{model_size}.pt')\n",
    "    \n",
    "    # Расширенные параметры обучения\n",
    "    train_params = {\n",
    "        'data': 'dataset.yaml',\n",
    "        'epochs': epochs,\n",
    "        'imgsz': 640,\n",
    "        'batch': 16,\n",
    "        'name': f'yolov8{model_size}_tools_detection',\n",
    "        'patience': 20,\n",
    "        'optimizer': 'AdamW',\n",
    "        'lr0': 0.001,\n",
    "        'lrf': 0.01,\n",
    "        'momentum': 0.937,\n",
    "        'weight_decay': 0.0005,\n",
    "        'augment': True,\n",
    "        'hsv_h': 0.015,\n",
    "        'hsv_s': 0.7,\n",
    "        'hsv_v': 0.4,\n",
    "        'degrees': 45.0,\n",
    "        'translate': 0.1,\n",
    "        'scale': 0.5,\n",
    "        'shear': 0.0,\n",
    "        'perspective': 0.0,\n",
    "        'flipud': 0.0,\n",
    "        'fliplr': 0.5,\n",
    "        'mosaic': 1.0,\n",
    "        'mixup': 0.1,\n",
    "        'copy_paste': 0.1,\n",
    "        'erasing': 0.4,\n",
    "        'dropout': 0.1,\n",
    "        'val': True,\n",
    "        'save': True,\n",
    "        'save_period': 10,\n",
    "        'device': 'cpu',  # Можно изменить на 'cuda' или 0 для GPU\n",
    "        'workers': 8,\n",
    "        'single_cls': False,\n",
    "        'verbose': True,\n",
    "        'exist_ok': True\n",
    "    }\n",
    "    \n",
    "    print(\"🎯 Начинаем обучение модели...\")\n",
    "    print(f\"📊 Параметры обучения: {epochs} эпох, размер батча: 16\")\n",
    "    print(f\"📁 Данные: {config['path']}\")\n",
    "    \n",
    "    # Обучаем модель\n",
    "    results = model.train(**train_params)\n",
    "    \n",
    "    print(\"✅ Обучение завершено!\")\n",
    "    return model, results\n",
    "\n",
    "def export_model_to_onnx(model, output_path='yolov8_tools.onnx'):\n",
    "    \"\"\"\n",
    "    Экспорт модели в формат ONNX с оптимизацией\n",
    "    \"\"\"\n",
    "    print(\"📤 Экспорт модели в ONNX...\")\n",
    "    \n",
    "    # Получаем путь к лучшей модели\n",
    "    model_path = model.trainer.best if hasattr(model.trainer, 'best') else 'runs/detect/yolov8s_tools_detection/weights/best.pt'\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        # Загружаем лучшую модель для экспорта\n",
    "        best_model = YOLO(model_path)\n",
    "        best_model.export(format='onnx', imgsz=640, simplify=True, dynamic=True, opset=12)\n",
    "        print(f\"✅ Модель экспортирована в: {output_path}\")\n",
    "    else:\n",
    "        # Экспортируем текущую модель\n",
    "        model.export(format='onnx', imgsz=640, simplify=True, dynamic=True, opset=12)\n",
    "        print(f\"✅ Модель экспортирована в: {output_path}\")\n",
    "\n",
    "def evaluate_model(model, data_path='yolo_dataset'):\n",
    "    \"\"\"\n",
    "    Оценка модели на тестовых данных\n",
    "    \"\"\"\n",
    "    print(\"📊 Оценка модели...\")\n",
    "    \n",
    "    try:\n",
    "        metrics = model.val(data=os.path.join(data_path, 'dataset.yaml'), split='val')\n",
    "        \n",
    "        print(\"📈 Результаты оценки:\")\n",
    "        print(f\"  mAP50: {metrics.box.map50:.4f}\")\n",
    "        print(f\"  mAP50-95: {metrics.box.map:.4f}\")\n",
    "        print(f\"  Precision: {metrics.box.mp:.4f}\")\n",
    "        print(f\"  Recall: {metrics.box.mr:.4f}\")\n",
    "        \n",
    "        return metrics\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Ошибка при оценке модели: {e}\")\n",
    "        return None\n",
    "\n",
    "def predict_on_image(model, image_path, conf_threshold=0.25, iou_threshold=0.45):\n",
    "    \"\"\"\n",
    "    Предсказание на одном изображении с улучшенной визуализацией\n",
    "    \"\"\"\n",
    "    # Проверяем существование файла\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"❌ Изображение не найдено: {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Выполняем предсказание\n",
    "    results = model(image_path, conf=conf_threshold, iou=iou_threshold, augment=False)\n",
    "    \n",
    "    # Визуализируем результаты\n",
    "    for i, result in enumerate(results):\n",
    "        # Рисуем bounding boxes с улучшенной визуализацией\n",
    "        img = result.plot(line_width=2, font_size=1.0, conf=True, labels=True)\n",
    "        \n",
    "        # Создаем окно с фиксированным размером\n",
    "        height, width = img.shape[:2]\n",
    "        max_display_size = 1200\n",
    "        if max(height, width) > max_display_size:\n",
    "            scale = max_display_size / max(height, width)\n",
    "            new_width = int(width * scale)\n",
    "            new_height = int(height * scale)\n",
    "            img = cv2.resize(img, (new_width, new_height))\n",
    "        \n",
    "        # Показываем изображение\n",
    "        cv2.imshow('Инструменты - обнаружение', img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        # Детальная информация об обнаруженных объектах\n",
    "        print(f\"\\n🔍 Результаты обнаружения для изображения {i+1}:\")\n",
    "        if len(result.boxes) > 0:\n",
    "            for j, box in enumerate(result.boxes):\n",
    "                class_id = int(box.cls[0])\n",
    "                confidence = float(box.conf[0])\n",
    "                bbox = box.xyxy[0].cpu().numpy()\n",
    "                class_name = model.names[class_id]\n",
    "                print(f\"  Объект {j+1}: {class_name} \"\n",
    "                      f\"(уверенность: {confidence:.3f}) \"\n",
    "                      f\"BBox: {bbox.astype(int)}\")\n",
    "        else:\n",
    "            print(\"  Объекты не обнаружены\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def predict_on_folder(model, folder_path, conf_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Предсказание на всех изображениях в папке\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"❌ Папка не найдена: {folder_path}\")\n",
    "        return\n",
    "    \n",
    "    image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')\n",
    "    images = [f for f in os.listdir(folder_path) if f.lower().endswith(image_extensions)]\n",
    "    \n",
    "    print(f\"🔍 Найдено {len(images)} изображений в папке {folder_path}\")\n",
    "    \n",
    "    for i, img_name in enumerate(images):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        print(f\"\\n📄 Обработка {i+1}/{len(images)}: {img_name}\")\n",
    "        predict_on_image(model, img_path, conf_threshold)\n",
    "\n",
    "def main():\n",
    "    # Пути к данным\n",
    "    dataset_path = '/data/vscode/HacatonAeroflot/Aeroflot-project/datasets/raw'\n",
    "    output_dir = '/data/vscode/HacatonAeroflot/Aeroflot-project/yolo_dataset'\n",
    "    \n",
    "    try:\n",
    "        # Проверяем существование пути\n",
    "        if not os.path.exists(dataset_path):\n",
    "            print(f\"❌ Ошибка: путь {dataset_path} не существует!\")\n",
    "            return\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(\"🛠️  СИСТЕМА ОБНАРУЖЕНИЯ ИНСТРУМЕНТОВ (УЛУЧШЕННАЯ)\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Шаг 1: Подготовка датасета\n",
    "        print(\"\\n📁 ШАГ 1: Подготовка датасета...\")\n",
    "        classes = prepare_yolo_dataset(dataset_path, output_dir)\n",
    "        \n",
    "        # Шаг 2: Создание конфигурации\n",
    "        print(\"\\n⚙️  ШАГ 2: Создание конфигурации...\")\n",
    "        config, classes = create_dataset_config(output_dir)\n",
    "        \n",
    "        if config is None:\n",
    "            raise ValueError(\"Не удалось создать конфигурацию датасета\")\n",
    "        \n",
    "        # Шаг 3: Обучение модели\n",
    "        print(\"\\n🎓 ШАГ 3: Обучение модели...\")\n",
    "        model, results = train_yolo_model(output_dir, model_size='s', epochs=100)\n",
    "        \n",
    "        # Шаг 4: Сохранение модели\n",
    "        print(\"\\n💾 ШАГ 4: Сохранение модели...\")\n",
    "        model.save('best_tools_detection.pt')\n",
    "        print(\"✅ Модель сохранена как 'best_tools_detection.pt'\")\n",
    "        \n",
    "        # Шаг 5: Экспорт в ONNX\n",
    "        print(\"\\n📤 ШАГ 5: Экспорт в ONNX...\")\n",
    "        export_model_to_onnx(model)\n",
    "        \n",
    "        # Шаг 6: Оценка модели\n",
    "        print(\"\\n📊 ШАГ 6: Оценка модели...\")\n",
    "        metrics = evaluate_model(model, output_dir)\n",
    "        \n",
    "        # Шаг 7: Тестирование на разных типах изображений\n",
    "        print(\"\\n🧪 ШАГ 7: Тестирование модели на разных типах изображений...\")\n",
    "        \n",
    "        test_types = ['val']  # Можно добавить 'train' для большего количества тестов\n",
    "        \n",
    "        for split in test_types:\n",
    "            test_dir = os.path.join(output_dir, 'images', split)\n",
    "            if os.path.exists(test_dir):\n",
    "                test_images = os.listdir(test_dir)\n",
    "                if test_images:\n",
    "                    # Тестируем на нескольких изображениях\n",
    "                    for i, test_img in enumerate(test_images[:3]):  # Первые 3 изображения\n",
    "                        test_image_path = os.path.join(test_dir, test_img)\n",
    "                        print(f\"\\n🔍 Тест {i+1}: {test_img}\")\n",
    "                        predict_on_image(model, test_image_path)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"✅ ВСЕ ЭТАПЫ ЗАВЕРШЕНЫ УСПЕШНО!\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ КРИТИЧЕСКАЯ ОШИБКА: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
